{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BA865 - Lecture 08 - Exercise Solutions.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMprpjzDNdl2o9EZ34OHQMu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/BA865/blob/master/BA865_Lecture_08_Exercise_Solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9fPT5sGgA9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "if not os.path.exists('./models'):\n",
        "  os.mkdir('./models')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AtrsfEMUYGcG"
      },
      "source": [
        "# Exercise: Train a CNN for labeling CIFAR-10 images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aPiDX_aSYGcR"
      },
      "source": [
        "While simple neural networks perform well for the MNIST data, they work badly for the CIFAR-10 images due to the complexity of these images that have three color channels. By using advanced architecture such as convolution layers, we will build a better model than the current one. \n",
        "\n",
        "Before writing a code block for an advanced model, let's think about its structure. First, we need to capture edges or other features in images. Convolution layers are what we need for this purpose. The number of output channels would be larger than the number of input channels to let the model learn many features as the following line.\n",
        "\n",
        "```python\n",
        "torch.nn.Conv2d(in_channels=3, out_channels=sizeOutChannels, kernel_size=3, padding=1)\n",
        "```\n",
        "\n",
        "Next, by adding a batch normalization layer, we can increase speed and performance of training. Note that `num_features` in the `BatchNorm2d` should match the `out_channels` in the previous convolution layer.\n",
        "\n",
        "```python\n",
        "torch.nn.BatchNorm2d(num_features = sizeOutChannels)\n",
        "```\n",
        "\n",
        "Any activation layer can be added after the batch normalization layer. In this lecture, we will use the ReLU function. \n",
        "\n",
        "```python\n",
        "torch.nn.ReLU()\n",
        "```\n",
        "\n",
        "Lastly, add a pooling layer to aggregate values. \n",
        "\n",
        "```python\n",
        "torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "```\n",
        "\n",
        "Our model is built on the combinations of convolution layers, batch normalization layers, activation layers, and pooling layers. \n",
        "\n",
        "Below, create a new model class called CnnCIFAR (it needs to inherit from `torch.nn.Module`).\n",
        "\n",
        "You can model it after the NN that we built above. However, to make your `forward` method simpler and to better organize your layers, you should  combine layers into logical blocks using `torch.nn.Sequential()`.\n",
        "\n",
        "In your constructor:\n",
        "- Don't forget to call the super's constructor first\n",
        "- add arguments `sizeOutChannels`(the out_channels of the Conv2D layer), `sizeHiddenLayer` (the out features of the fully connected linear layer) to your constructor.\n",
        "- define a convolution layer block that consists of sequential layers of:\n",
        " - a Conv2d\n",
        " - a BatchNorm2d\n",
        " - a ReLU\n",
        " - a MaxPool2d (`kernel_size=2`, `stride=2`)\n",
        "- define a fully connected layer block that consists of sequential layers of:\n",
        " - a linear layer with the appropriate input feature size to match the output of the convolution layer (it will be some number *`sizeOutChannels` -- you'll have to figure out what that number is based on the `kernel_size` and `stride` of the MaxPool2d layer) and the output size given by our argument `sizeHiddenLayer`\n",
        " - a ReLU\n",
        " - a Dropout (`p=0.2`)\n",
        " - another linear layer with output size of 10 (for each of the 10 classes a CIFAR image can belong to).\n",
        "\n",
        "Define your `forward` method to pass the input x through the logical layer blocks that are defined in your constructor.\n",
        "- IMPORTANT: you'll want to flatten the output of the convolution layer block before passing it into the fully connected layer block. You can do this with `x.view(x.size(0),-1)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKE4HWYiVr-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write you CnnCifar class here\n",
        "class CnnCIFAR(torch.nn.Module):\n",
        "  def __init__(self, sizeOutChannels, sizeHiddenLayer):\n",
        "    super(CnnCIFAR, self).__init__()\n",
        "    self.conv_layer = torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(in_channels=3, out_channels=sizeOutChannels, kernel_size=3, padding=1),\n",
        "        torch.nn.BatchNorm2d(num_features = sizeOutChannels),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc_layer = torch.nn.Sequential(\n",
        "        torch.nn.Linear(sizeOutChannels*16*16, sizeHiddenLayer),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Dropout(p=0.2),\n",
        "        torch.nn.Linear(sizeHiddenLayer, 10) # return values to predict a class among 10 labels.\n",
        "    )  \n",
        "\n",
        "  def forward(self, x):\n",
        "    # conv_layer\n",
        "    x = self.conv_layer(x)\n",
        "    # flatten\n",
        "    x = x.view(x.size(0), -1)\n",
        "    # fc_layer\n",
        "    x = self.fc_layer(x)\n",
        "    return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvaA3onNyr1R",
        "colab_type": "text"
      },
      "source": [
        "In `self.fc_layer`, why does `torch.nn.Linear` accept an input of length sizeOutChannels $\\times$ 16 $\\times$ 16? It depends on the `kernel_size` and `stride` that determine the size of returns of the convolution layer. Imagine the structure of the convolution neural network that processes a 32 $\\times$ 32 matrix and check whether the size of the first input of `fc_layer` is correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HsUDKFJa_4S",
        "colab_type": "text"
      },
      "source": [
        "Run the below code (to ensure that CIFAR10 is loaded and transformed properly, in case a session disconnect happened earlier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGqnWAc7eBIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the CIFAR10 data\n",
        "transform_cifar = transforms.Compose( [ transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ] )\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_cifar)\n",
        "testset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_cifar = DataLoader(trainset_cifar, batch_size=batch_size, shuffle=True)\n",
        "test_dl_cifar = DataLoader(testset_cifar, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BCbi4-AxFyx",
        "colab_type": "text"
      },
      "source": [
        "We can see how tensors change shape as they move through the different layers of our NN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0WGGi_nQWEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb1,yb1 = next(iter(train_dl_cifar))\n",
        "print(xb1.shape)\n",
        "foo = torch.nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,padding=1)\n",
        "xb2 = foo(xb1)\n",
        "print(xb2.shape)\n",
        "bar = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "xb3=bar(xb2)\n",
        "print(xb3.shape)\n",
        "xb4 = xb3.view(xb3.size(0),-1)\n",
        "print(xb4.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QleVIE1rbhvt",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to define the model with the given arguments for `sizeOutChannels`, `sizeHiddenLayer` and to define a loss function (here we'll use the cross entropy loss) and optimizer (here we'll use Stochastic Gradient Descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoBup_-qfwME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnCIFAR = CnnCIFAR(sizeOutChannels = 16, sizeHiddenLayer = 50)\n",
        "cnnCIFAR = cnnCIFAR.cuda() # define the model for cuda\n",
        "\n",
        "cnn_CIFAR_loss_fn = torch.nn.CrossEntropyLoss() # use cross entropy loss\n",
        "cnn_CIFAR_opt = torch.optim.SGD(cnnCIFAR.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PukJ4aaIqTxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnCIFAR.train()\n",
        "# We will train the model for 15 epochs as same as the previous fully connected network.\n",
        "for epoch in range(15):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_dl_cifar:\n",
        "        # data to train\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # intitiate gradients\n",
        "        cnn_CIFAR_opt.zero_grad()\n",
        "\n",
        "        # calculate loss and update parameters\n",
        "        outputs = cnnCIFAR(inputs)\n",
        "        loss = cnn_CIFAR_loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        cnn_CIFAR_opt.step()\n",
        "\n",
        "        # Sum losses\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} loss = {running_loss/len(train_dl_cifar)}\") # print out the loss (averaged over all the predictions in the batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYlwo7XP0aBm",
        "colab_type": "text"
      },
      "source": [
        "Let's evaluate the trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP42jRmKieoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnnCIFAR.eval() # put the model into evaluation mode -- may affect some types of layers (e.g., dropout)\n",
        "with torch.no_grad():\n",
        "  running_loss = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  numClasses = len(test_dl_cifar.dataset.classes)\n",
        "  cm = np.zeros((numClasses,numClasses),dtype=np.int32) # an empty matrix to hold the confusion matrix, we'll sum the confusion matrices for each batch\n",
        "  for xb, yb in test_dl_cifar:\n",
        "    xb = xb.cuda()\n",
        "    yb = yb.cuda()\n",
        "    pred = cnnCIFAR(xb)\n",
        "    predLabels = torch.argmax(pred,dim=1)\n",
        "    cm += confusion_matrix(yb.cpu().numpy(),predLabels.cpu().numpy(),range(0,10)) # add this batch's confusion matrix to the total matrix -- we have to specify the list of class indexes, or sklearn will shorten our cm to only the classes seen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb1YNseJrkg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = np.diag(cm)/cm.sum(axis=1)\n",
        "print(cm, '\\n', acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XF5GNvr4coH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Accuracy of the convolution neural network: \", np.mean(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZwMDmJ1Bmq",
        "colab_type": "text"
      },
      "source": [
        "The convolution neural network performs better than the previous fully connected network. Could we still do better? We only added one convolutional layer block. But these images belong to many different classes.  You should now go back and try to experiment with the model. What if you run it for more epochs? What if you try changing the arguments for our model (e.g., try adjusting the parameters `sizeOutChannels`, `sizeHiddenLayer`). You could also try adding another convolutional layer blocks.  Remember the final output needs to match the number of classes we're trying to predict.  See if you can do better. Don't be afraid to google around for examples of CNN's applied to images. What do they do? What kind of performance can they achive on CIFAR (this is a well known and standard dataset).  "
      ]
    }
  ]
}