{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BA865 - Lecture 06.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "NsClHywMkHe0",
        "YBabsccpk5Fw",
        "gpXWoYxykojF"
      ],
      "authorship_tag": "ABX9TyN10onTJb8Q+Bu+sMSVDq+b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/BA865/blob/master/BA865_Lecture_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsClHywMkHe0",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65kFoHxVkLIg",
        "colab_type": "text"
      },
      "source": [
        "This lecture focuses on the theory of neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AtRyQECkTRb",
        "colab_type": "text"
      },
      "source": [
        "# From Real Neurons to Artificial Neurons\n",
        "\n",
        "Artificial neural networks were of course inspired by how the real neurons inside of our brains work.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=15D4uFFIloOQE0oYU6Zt8wYrN3VxSn12-\" width=5000>\n",
        "\n",
        "Left:\n",
        "* a picture of an actual neuron in our brain. I won't go into the details of how this work (its mostly biology that isn't that useful for our purposes).\n",
        "\n",
        "Right:\n",
        "* a model of an artificial neuron. \n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Each neuron in our brain gets inputs from many other neurons. It only fires (activates) when these inputs combine to be greater than a certain threshold.\n",
        "\n",
        "Each input into an artificial neuron is multiplied by some weight and then these values are all summed together. If the resultant sum is greater than some threshold, the neuron fires.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Mathematically, the mapping of input to output of this artifical neuron is:\n",
        "\n",
        "$\\hspace{5cm}y = \\delta(\\sum_i{w_i x_i} + b)$\n",
        "\n",
        "where:\n",
        "- $w_i$ are the weights\n",
        "- $b$ is the bias\n",
        "- $\\delta()$ is a step function (=1 if its argument is > 0; =0 otherwise)\n",
        "- note: $\\sum_i{w_i x_i}$ can be thought of as a vector dot product, $\\vec{w}\\cdot\\vec{x}$\n",
        "\n",
        "<br>\n",
        "\n",
        "We chose a step function ($\\delta$) as the **activation function**. Activation functions transform the weighted inputs of a neuron to determine whether it activates. However, there are other choices we could have made (e.g., sigmoid, RELU -- we'll talk more about these later).\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Just like a real neuron, an artificial neuron is *adaptive* -- it can be trained by adjusting its parameters (the weights and biases).\n",
        "\n",
        "<br>\n",
        "\n",
        "The example shown above is for a single neuron. It is termed the **single-layer perceptron**.  However, you can imagine that is is possible to chain a bunch of such neurons together to create a network. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ptC9O5qUGw",
        "colab_type": "text"
      },
      "source": [
        "# A neural network\n",
        "\n",
        "Typically, we think of a neural network as a set of layers between the input and output:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=14nhiGsQVECw_XjVm7-WBftnntfYzvv0D\">\n",
        "\n",
        "The *width* of a layer is the number of neurons it contains. The *depth* of a neural network is the number of layers it contains.\n",
        "\n",
        "So, the \"deep learning\" you have likely heard about refers to building and training neural networks that have many layers.\n",
        "\n",
        "Two aspects of a Neural Network are:\n",
        "- The neural network **architecture**: This describes the connections between neurons in each layer. Above, I showed you a neural net with several \"fully connected\" layers. However there are various choices for architecture that we will talk about.\n",
        "- The neural network **training procedure**: This describes the procedure that we use to train a neural network.\n",
        "\n",
        "\n",
        "Each nueron (each circle or node in the example diagram above) has a particular bias associated with it and associates a different weight for each of its inputs (the edges in the diagram above):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=12RwFK6JFws0f9cOoK0d_aIGW_CrGKsmu\" width=500>\n",
        "\n",
        "(notice our neuron model now explicitly has the bias incorporated and a generalized activation function)\n",
        "\n",
        "\n",
        "As you can imagine, the number of parameters in a deep neural network can be quite large. How do we go about finding the right values of these parameters?  By \"right values of the parameters\", I mean the values that produce the output we want given the input.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQE_56BUrxk0",
        "colab_type": "text"
      },
      "source": [
        "# Training a neural network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk6rppi8sxEO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://drive.google.com/uc?id=10-kg9Mb-04hSeTUUW_bNQKSnDr7FMKIs\">\n",
        "\n",
        "Every neural network is essentially an approximation of a function. We are trying to approximate the function that, when it operates on the inputs will return the targets.  However, because it is an approximation, there will always be some *error*.  We term this error the \"loss\". The error depends on the parameters of the network (the weights and biases) -- and remember that there are usually a lot of parameters.\n",
        "\n",
        "Training a neural network is an optimization problem. We are seeking a \"global minimum\" - i.e., the values of the parameters that minimize the loss.\n",
        "\n",
        "Training is accomplished by implementing a **training loop**, which *loops over epochs* and does the following loop in <font color=blue>pseudo-code</font>:\n",
        "\n",
        "```python\n",
        "for epoch in epochs:\n",
        "  predictions = net.forward(inputs) # 1. feedforward\n",
        "  loss = loss_function(predictions, targets) # 2. calculate loss\n",
        "  loss.backward() # 3. Backpropagate\n",
        "  optimizer.step(net.parameters) # update parameters (weights, biases)\n",
        "  zero_gradients() # set the gradients to zero\n",
        "```\n",
        "\n",
        "1. **Feedforward** - pass the input data into the network to determine the predictions (the response of the network to the inputs).\n",
        " - This is accomplished by calling the `model(inputs)` or by calling `net.forward(inputs)` depending on how the network has been defined (more on this later)\n",
        "2. **Calculate loss** - Calculate the loss by comparing the predictions to the targets\n",
        " - This is accomplished by calling `loss_function(predictions,targets)` where `loss_function()` is a loss function (there are many to choose from, more on this later) \n",
        "3. **Backpropagate** the loss - calculate the gradients of the parameters (biases and weights) using `loss.backward()`\n",
        "4. **Update the parameters** - Update the weights and biases to reduce the loss\n",
        " - This is accomplished through an update function or (more commonly) through a built in optimizer, `optimizer.step()` where `optimizer` is an optimizer object (there are many to choose from, more on this later)\n",
        " - We have to be careful to zero out the gradients after each epoch (each pass through the loop), because gradients accumulate.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJCOSZWlBXrZ",
        "colab_type": "text"
      },
      "source": [
        "# Videos \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAsadkGtBfD4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "At this point, we have enough of an idea about what neural networks are and how we train them, that watching a couple of very well-animated movies would be a perfect breather.\n",
        "\n",
        "Get your popcorn out!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgsVQGoEDPqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3Blue1Brown \"But what is a Neural Network?\"\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('aircAruvnKk',width=900,height=700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfIqvmEfFIJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3Blue1Brown \"Gradient Descent, how neural networks learn\"\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('IHZwWFHWa-w',width=900,height=700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwFu34ApFVM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3Blue1Brown \"What is backpropagation really doing?\"\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('Ilg3gGewQ5U',width=900,height=700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSTTqobvFgC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3Blue1Brown \"Backpropagation Calculus\" -- ONLY FOR THE BRAVE-HEARTED!\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('tIeHLnjs5U8',width=900,height=700)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwmtAb68zMn",
        "colab_type": "text"
      },
      "source": [
        "# Different Architectures?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNvcz4HZ8zle",
        "colab_type": "text"
      },
      "source": [
        "As we will soon see, there are many different types of neuron layers and ways to connect them to one another. The situation is not as simple as a bunch of fully connected layers in between an input and output layer. \n",
        "\n",
        "Different layers include:\n",
        "- pooling layers - perform some aggregate operation on a group of neurons from the last layer.\n",
        "- convolution layers - apply some operation to a \"sliding window\" over a group of neurons from the last layer.\n",
        "- normalization layers - adjust the outputs from a past layer so they don't get \"out of control\". e.g., adjust the outputs by subtracting the mean and dividing by the standard deviation.\n",
        "\n",
        "Beyond layers, there are also completely different architectures. For example, <font color=blue>recursive neural networks (RNNs)</font> which are ideal for working with sequence data, consume each element of the sequence as an input and then produce an output that also feeds back into itself as another input (hence the term recursive):\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1Q3VuMWj_llhpxPwXDyas2uQ3pAmQRBrO\" width=500>\n",
        "\n",
        "In the picture above, there is **only a single RNN cell** (it is repeated to illustrate how it is used with a sequence of input data). We feed it input 1, it output a hidden state (and possibly output 1) that we feed back into itself along with input 2.  This repeats until we reach the end of the sequence, at which point we look at the output.\n",
        "\n",
        "We'll talk more about architectures later, both in terms of individual layers and what they do and entire network architectures that are designed for a specific purpose.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ctyKNt88UY",
        "colab_type": "text"
      },
      "source": [
        "# Which Activation Function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJT_eyWmki6q",
        "colab_type": "text"
      },
      "source": [
        "There are a variety of different activation functions that can be used:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBabsccpk5Fw",
        "colab_type": "text"
      },
      "source": [
        "### Sigmoid (Logistic) and Hyperbolic Tangent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVtojaYIk8vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 20, 'figure.figsize': (10, 5)}) # set font and plot size\n",
        "x=np.arange(-10.,11,0.01)\n",
        "y1=(lambda x: 1/(1+np.exp(-x))) (x)\n",
        "y2=(lambda x: np.tanh(x)) (x)\n",
        "plt.plot(x,y1,'b');\n",
        "plt.plot(x,y2,'g');\n",
        "plt.grid();\n",
        "plt.xlabel('x');\n",
        "plt.ylabel('f(x)');\n",
        "plt.text(-9,0.5,'Sigmoid\\n'+r'$f(x) = \\frac{1}{1+e^{-x}}$',color=\"b\");\n",
        "plt.text(-9,-0.5,'Hyperbolic Tangent\\n'+r'$f(x) = tanh(x)$',color=\"g\");\n",
        "plt.plot(x,np.zeros(x.shape),'r:');\n",
        "plt.plot(x,np.ones(x.shape),'r:');\n",
        "plt.plot(x,-1*np.ones(x.shape),'r:');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k_6KRFIk7Yp",
        "colab_type": "text"
      },
      "source": [
        "Both the sigmoid and the hyperbolic tangent are the most traditional activiation function. They are defined as:\n",
        "\n",
        "$f(x) = \\frac{1}{1+e^{-x}}$ (sigmoid)\n",
        "\n",
        "$f(x) = tanh(x) = \\frac{2}{1+e^{-2x}}-1$ (hyperbolic tangent)\n",
        "\n",
        "Sigmoid ranges between 0 and 1 and is a \"softer\" version of the step function. While hyperbolic tangent ranges between -1 and 1 and is a bit steeper than the sigmoid (which can lead to faster training).\n",
        "\n",
        "However, in very deep neural nets (or recurring neural nets, which we'll talk about later), its use can lead to the ***vanishing gradient problem***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpXWoYxykojF",
        "colab_type": "text"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZb9CrnypIkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 20, 'figure.figsize': (10, 5)}) # set font and plot size\n",
        "x=np.arange(-0.1,0.2,0.01)\n",
        "y=(lambda x: np.maximum(0, x)) (x)\n",
        "plt.plot( x,y,'b-');\n",
        "plt.grid()\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('f(x)')\n",
        "plt.text(-0.07,0.13,'ReLU\\n'+r'$f(x) = max( 0, x)$',color=\"b\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSZqFO5PkoWg",
        "colab_type": "text"
      },
      "source": [
        "ReLU (Which stand for rectified linear unit) is a popular choice recently. It is defined as:\n",
        "\n",
        "$f(x) = max(0,x)$\n",
        "\n",
        "In other words it is equal to the input when the input is positive, but zero when the input is negative.  ReLU reduces the vanishing gradient problem significantly without any added expense that other solutions have. For this reason, it has become popular for training deep or recurrent neural nets. \n",
        "\n",
        "However it can suffer from the \"Dead Neuron\" or \"Dying ReLU\" problem: When learning rates are high, a substantial fraction of the network can be dead -- i.e., neurons that never activate once across the entire training dataset. This can happen when a neuron learns a large negative bias -- not only will the output of ReLU be zero, but also the gradient will be zero. At this point the neuron has irreversibly become dead (there's no way to update the bias).  \n",
        "\n",
        "ReLUs are often not used for the final output layer, since we typically want an output that is bounded or has a nice intrepretation (e.g., a probabilistic one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko5acyZukiyh",
        "colab_type": "text"
      },
      "source": [
        "### Leaky ReLU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cGU_DFkjcC",
        "colab_type": "text"
      },
      "source": [
        "The leaky ReLU was designed as a way to fix the \"Dying ReLU\" problem. The idea is to prevent the gradient of the activation function from becoming zero for any value of input.  \n",
        "\n",
        "$ f(x) = max(0.01x,x)$\n",
        "\n",
        "I won't show the plot, because it looks exactly like ReLU to the naked eye.  Some variants use 0.1x instead of 0.01x . Either way the \"leakiness\" is constant and just give some chance for a dead neuron to recover (since the gradient is constant and small even for large negative values of input)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utMxrY2dkgJM",
        "colab_type": "text"
      },
      "source": [
        "### Parameterized Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSBgnDgvka6v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "There are several other activation functions that can actually take parameters that can be learned through the training process. They are motivated by the two problems I mentioned above (vanishing gradient, dead neuron). And they do address these problems a bit better, however they come the cost of significantly increasing the parameters in the NN. I'm not going to talk about these in any detail, except to just mention two of them:\n",
        "\n",
        "- Parametrized ReLU: $f(x) = max(ax, x)$  where $a$ is a learned parameter\n",
        "- Exponential Linear Unit (ELU): $f(x) = max( a(e^{x}-1) , x)$ where $a$ is a learned parameter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yY-4L3uCIO",
        "colab_type": "text"
      },
      "source": [
        "## Last Layer Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9waA9rNMuFi4",
        "colab_type": "text"
      },
      "source": [
        "So far we have talked about activation functions that transform the output of a single neuron. However, there are also activiation functions that transform the output of a group of neurons.\n",
        "\n",
        "It is very common to add a final layer to neural nets that transforms the output to something that can be interpreted as a probability. For example, if the final output is of size N, (e.g., in a multi-class classification network) then we would want every one of the N numbers to be between (0,1) and we would also want their sum to equal 1. \n",
        "\n",
        "<font color=blue>Softmax</font> is an activation layer that accomplishes this, by doing the following transformation:\n",
        "$S_i(\\vec{x}) = \\frac{exp(x_i)}{\\sum_k{exp(x_k)}}$ \n",
        "\n",
        "where $S_i$ is the $i^{th}$ output and $\\vec{x}$ is the input vector. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLm5csPAAxbC",
        "colab_type": "text"
      },
      "source": [
        "# Which Loss Function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSpzxgfOAyIK",
        "colab_type": "text"
      },
      "source": [
        "The loss function you used is very important and it depends on the type of problem you want your neural network to solve.  This could be:\n",
        "- Functional Approximation e.g., regression \n",
        "- Binary classification e.g., is this image a dog or not?\n",
        "- Multi classification e.g., which genre does this movie belong to?\n",
        "- Autoencoding e.g., get a vector representation of some text\n",
        "\n",
        "In what follows, I will show you some loss functions in terms of predicted value $p$ and target value $t$. But of course, the loss must be summed over all predictions/targets: \n",
        "\n",
        "## Mean Absolute Error Loss\n",
        "\n",
        "$Loss(p,t) = | p - t| $\n",
        "\n",
        "This is simply the absolute magnitude of the difference between the predicted and target values. This is also called the \"L1 norm\". This is useful for very simple models and linear regression, though it is not often used even in these cases, because Mean Squared Error also captures this difference and is more traditional (and thus, more easily compared to e.g., actual linear regression). This is not very useful for the more complex networks that are used in most machine learning applications. \n",
        "\n",
        "## Mean Squared Error Loss\n",
        "$Loss(p,t) = (p -t)^2$\n",
        "\n",
        "This measure the square of the difference between the prediction and target, and you are probably already familiar with it. Unlike the absolute error, the MSE loss penalizes big mistakes more (because of the square). This is also called the \"L2 norm\".  It's useful for regression and problems where numerical values are not very large and where the number of dimensions are not very large. \n",
        "\n",
        "## Smooth L1 Loss\n",
        "$Loss(p,t) = \\begin{cases} \n",
        "\\frac{1}{2}*(p - t)^2, &\\text{if}\\ |p -t| <1\\\\ \n",
        "|p - t| - \\frac{1}{2},&\\text{otherwise} \\end{cases}\n",
        "$\n",
        "\n",
        "This is not as sensitive to outliers as the MSE (because it switches to absolute value when the difference between prediction and target is high). Thus it is more suitable when values can be large (and this differences between target and prediction can be large). It can be used for many problems.\n",
        "\n",
        "## Cross Entropy / Negative Log Likelihood Loss\n",
        "For classification problems, one often designs neural networks to output the probability (as $p$) of an input belonging to each of the possible classes. The target in this case will be a \"one-hot vector\" i.e., a vector with all zeroes except for the position of the correct class. The Negative Log Likelihood Loss is then given by:\n",
        "\n",
        "$Loss(p,t) = -log(\\vec{p}\\cdot\\vec{t})$\n",
        "\n",
        "Notice that because probabilities fall between (0,1) the log will be negative, hence the negative sign cancels this negative to make the loss positive for all cases. This penalizes a model that assigns low probabilities to the correct class. Wrong predictions do not explicitly get penalized. This is useful for classification problems. If you are familiar with entropy and cross-entropy, you will know that minimizing the cross-entropy is the same as minimizing the Negative Log Likelihood. If not, you can read more about it and the related KL-divergence [here](https://machinelearningmastery.com/cross-entropy-for-machine-learning/). This is useful for binary or multi-class prediction problems.\n",
        "\n",
        "\n",
        "These are just to give you a general idea. There are of course many other loss functions that often depend on what you are trying to accomplish with your neural network.  And you may even choose to construct your own loss function. For example, you may want build a neural network that tries to predict whether two sentences came from the same book. You might have a term in your loss function that punishes the NN for making the wrong prediction proportional to how different the actual sentences are by some metric. Whatever the case, the loss function is responsible for ensuring that your network does what you want it to -- and is thus a critical choice in the design of a neural net.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6pdfp061k9E",
        "colab_type": "text"
      },
      "source": [
        "# Which Optimizer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4H8zQTu1sr2",
        "colab_type": "text"
      },
      "source": [
        "Perhaps the most well known optimizer is <font color=blue>Stochastic Gradient Descent</font> or other variants of Gradient Descent. Another popular choice is <font color=blue>Adam</font> (Adaptive Moment Estimatation) which you can read more about [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/). \n",
        "\n",
        "It is important to choose the right optimizer because it will determine how long it takes to train your neural network to achieve good performance. This will also depend on how much training data you have. \n",
        "\n",
        "All optimizer are trying to determine the best direction in the parameter space to move in the next step, to travel towards <font color=blue>a global minimum</font>\n",
        "<br><br>\n",
        "Optimizers vary in their choice of:\n",
        "- how big the next step should be (<font color=blue>learning rate</font>)\n",
        "- whether the size of steps should be the same in all parameter directions or whether it is <font color=blue>adaptive</font> with  different learning rates for each parameter\n",
        "- whether it should have <font color=blue>momentum</font> -- i.e., tend to move in the same direction of its last move.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}