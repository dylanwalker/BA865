{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BA865 - Lecture 08.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlX90KmQBx4KDd0poD8xHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanwalker/BA865/blob/master/BA865_Lecture_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4oWkG_ETgeC",
        "colab_type": "text"
      },
      "source": [
        "# Code Preface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5NVjxzRTgBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO7_L8xo7xnl",
        "colab_type": "text"
      },
      "source": [
        "# Defining Neural Network Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy7UwfaeSYUr",
        "colab_type": "text"
      },
      "source": [
        "In the past examples, we have discussed have multi-layered neural networks, but haven't actually shown any. We built a simply linear model using `nn.linear()`, but how do you build more complex architectures by using pytorch's existing layers?  \n",
        "\n",
        "There are two conventional ways to do this:\n",
        "1. Chain layers together using `torch.nn.Sequential()`\n",
        "2. Create a class for your neural network that inherits from the `torch.nn.Module` base class and  implements the `forward()` method in it.\n",
        "\n",
        "I will show examples of these two approaches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ITc86b7sxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.nn.Sequential(torch.nn.Linear(3,8),torch.nn.ReLU(),torch.nn.Linear(8,2),torch.nn.ReLU(),torch.nn.Softmax(dim=0))\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXdZAq5ifMVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.rand(5,3)\n",
        "model(torch.rand(5,3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51mGMBOooALV",
        "colab_type": "text"
      },
      "source": [
        "The sequential approach works when you have a simple network, but an alternative (and much more configurable and robust) approach is to define a class with a constructor and a `forward()` method: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5MLphuNVi7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    # The constructor calls the base class constructor and then defines the layers that will be used (ordering doesn't matter here, as layers are just properties)\n",
        "    super().__init__()\n",
        "    self.fc1 = torch.nn.Linear(3,8)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(8,2)\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "    self.softmax = torch.nn.Softmax(dim=0)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    # The forward() method describes how an input tensor (the argument x) will be passed through the layers.\n",
        "    # Here, the order matters.\n",
        "    # Also note that we can do other things to the data at any point between the layers (such as functionally transform it in some way)\n",
        "    #  -- we could add noise to the data somewhere in between some layers, normalize it, randomly drop or forget some of it... etc.\n",
        "    #  Advance NN approaches will often use such tricks. \n",
        "    x = self.fc1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aIIZUsSTdKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BasicNet()\n",
        "y = model.forward(torch.rand(5,3))\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoqnQPQEQFSR",
        "colab_type": "text"
      },
      "source": [
        "I'd like to turn our attention to architecture in pytorch but before I do that, because many of the concepts apply to tensor data that is 2D or higher, we'll take a brief foray into `torchvision` and image processing, so I can explain how we represent images as tensors.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJas2SQWMUcb",
        "colab_type": "text"
      },
      "source": [
        "# Working with Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tg0yB94MXXz",
        "colab_type": "text"
      },
      "source": [
        "Pytorch has a bunch of useful utilities for working with image data under the `torchvision` module. \n",
        "\n",
        "Let's look at some example image datasets and how to use some of these utilities in practice. This will put us in a better position to discuss architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wk0QjprUdkU",
        "colab_type": "text"
      },
      "source": [
        "First we'll need to import a bunch of modules:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2gUetvrP5P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuVamcCiUk3N",
        "colab_type": "text"
      },
      "source": [
        "We'll use one of the datasets built into torchvision called CIFAR10, a dataset of 60,000 32x32 pixel images -- each belonging to one of ten classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) that is described in detail [here](https://www.cs.toronto.edu/~kriz/cifar.html). (btw, CIFAR stands for Canadian Institute for Advanaced Research, though I always think of it as \"Can It Fly And Run\"). \n",
        "\n",
        "We'll use `torchvision.datasets.CIFAR10()` but we don't want to work with the raw image data alone as it is delivered as a set of PIL (Python Image Library) image objects. We'll want to convert _each color channel of the image_ to a tensor and then normalize it so that the values all fall between (-1,1). \n",
        "\n",
        "To accomplish this, we'll use a tool from torchvision's transforms module, `transforms.Compose()` which lets us chain a bunch of transformations together. We'll chain `transforms.ToTensor()` and `transforms.Normalize()`, which takes the mean and std for each of the three color channels. If you work on images, there are tons of useful image transformation in torchvision "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVskZ4pFQZyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chain a bunch of transformations together us torchvision.transforms.Compose\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))]) # First make the input data a tensor, then apply a normalization to each of the 3 color channels of the image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBPmTKU8X0lb",
        "colab_type": "text"
      },
      "source": [
        "With those transforms defined, we can actually grab the dataset and apply the chain of transformations all in one line of code. The method to download and load CIFAR10 also allows you to set the argument `train=True` if you are going to use the images to train a NN (as opposed to testing it). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw2qJf0AQrxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab training data from one of the built-in datasets (CIFAR10)\n",
        "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
        "                                        download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGpdG6hdbAGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QtzhuOjcd6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset.data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSwx5LiEbBjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma40agKxYH6K",
        "colab_type": "text"
      },
      "source": [
        "Just to see what one image looks like as a bunch of tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRfrlz2XSmbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exampleImage, exampleClassLabel = trainset[0]\n",
        "print(exampleImage.shape) # 3 different 32x32 tensors (one for each color channel) -- Each of the 32x32 values represents the intensity of the color for that pixel \n",
        "print(exampleImage)\n",
        "print(exampleClassLabel) # the class label; we have to look at trainset.classes to see what this means"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge03KY3eY4Pa",
        "colab_type": "text"
      },
      "source": [
        "We'll want some way to show one of these color channels, so we'll make a quick function to do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNUmbIlmZg6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "  img = img/2 + 0.5 # undo our normalization, just to show the image, because plt's imshow() expects numbers to be between (0,1)\n",
        "  img = img.numpy() # plt's imshow() knows how to work with numpy arrays, not tensors, so we'll convert it first\n",
        "  plt.imshow(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJtHESSEc4rd",
        "colab_type": "text"
      },
      "source": [
        "Now lets grab a random example item from our dataset. We know there are 50,000 ( `trainset.data.shape[0]` ) items, so we'll use `np.random.randint()` to grab an index int this range, then we'll display just one of the color channels using our custom `imshow()` function. \n",
        "\n",
        "You should run this a few times, to get a feel for the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiSAmHmfSiS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imshow(exampleImage[0])\n",
        "\n",
        "exItem = trainset[ np.random.randint(0,trainset.data.shape[0]) ] # note that exItem is a tuple, so exItem[0] is the image and exItem[1] is the class label index\n",
        "colorChannel = 0 # You can change this to 1 or 2 if you'd like to see a different color channel\n",
        "imshow(exItem[0][colorChannel])\n",
        "print(trainset.classes[exItem[1]]) # remember trainset.classes is a list of the class labels, so this will translate the class label index (an int) into the class label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RgXChWPPiK3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "This same approach can be used to work with other image datasets, though the particulars (the number of pixels, color channels) may differ.\n",
        "\n",
        "Now that you understand how images are represented as tensors, we can talk about the architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN0PzKHJX33o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpak2tSMR9Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def imshow(img):\n",
        "  if img.shape[0]==3: # its probably (color,width,height) so make it (width,height,color) which is what plt.imshow() wants\n",
        "    img = img.transpose(1,2,0)\n",
        "  img = img/2 + 0.5 \n",
        "  img = img.cpu().numpy()\n",
        "  plt.imshow(img)\n",
        "\n",
        "class ImgNet(torch.nn.Module):\n",
        "  def __init__(self,sizeInput,sizeHiddenLayer1,sizeHiddenLayer2,sizeOutput):\n",
        "    super().__init__()\n",
        "    self.fc1 = torch.nn.Linear(sizeInput,sizeHiddenLayer1)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.fc2 = torch.nn.Linear(sizeHiddenLayer1,sizeHiddenLayer2)\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "    self.fc3 = torch.nn.Linear(sizeHiddenLayer2,sizeOutput)\n",
        "    self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.logsoftmax(x)\n",
        "    return x\n",
        "\n",
        "def fit(num_epochs, model, train_dl, loss_fn, opt):\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss=0\n",
        "    for xb,yb in train_dl: \n",
        "      xb = xb.view(xb.shape[0],-1)\n",
        "      xb = xb.to(\"cuda\")\n",
        "      yb = yb.to(\"cuda\")\n",
        "      opt.zero_grad()\n",
        "      pred = model(xb)\n",
        "      loss = loss_fn(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      running_loss+=loss.item()\n",
        "    print(f\"Epoch {epoch} loss = {running_loss/len(train_dl)}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDUfCiS6swD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST\n",
        "transform_mnist = transforms.Compose( [transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,)) ] )\n",
        "trainset_mnist = torchvision.datasets.MNIST('./mnist', download=True, train=True, transform=transform_mnist)\n",
        "testset_mnist = torchvision.datasets.MNIST('./mnist', download=True, train=False, transform=transform_mnist)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_mnist = DataLoader(trainset_mnist, batch_size=batch_size, shuffle=True)\n",
        "test_dl_mnist = DataLoader(testset_mnist, batch_size=batch_size, shuffle=True)\n",
        "imgnet_mnist = ImgNet(28*28,128,64,10).cuda()\n",
        "\n",
        "loss_fn_mnist = torch.nn.functional.nll_loss\n",
        "opt_mnist = torch.optim.SGD(imgnet_mnist.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo.\n",
        "fit(15, imgnet_mnist, train_dl_mnist, loss_fn_mnist, opt_mnist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PfN_n-ttKmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = next(iter(test_dl_mnist))\n",
        "img = images[0].to(\"cuda\")\n",
        "label = labels[0].to(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  predLabel = torch.argmax(imgnet_mnist(img.view(1,-1))).item()\n",
        "\n",
        "imshow(img.view(28,28))\n",
        "print(f\"Predicted label was: {predLabel}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQFeLRidszwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR10\n",
        "transform_cifar = transforms.Compose( [ transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ] )\n",
        "trainset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_cifar)\n",
        "testset_cifar = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "batch_size = 64\n",
        "train_dl_cifar = DataLoader(trainset_cifar, batch_size=batch_size, shuffle=True)\n",
        "test_dl_cifar = DataLoader(testset_cifar, batch_size=batch_size, shuffle=True)\n",
        "imgnet_cifar = ImgNet(3*32*32,128,64,10).cuda()\n",
        "\n",
        "loss_fn_cifar = torch.nn.functional.nll_loss\n",
        "opt_cifar = torch.optim.SGD(imgnet_cifar.parameters(), lr=0.003, momentum=0.9) # where did I get these \"magic numbers?\"  Trial and error and voodoo.\n",
        "fit(50, imgnet_cifar, train_dl_cifar, loss_fn_cifar, opt_cifar)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKMi40n1w3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = next(iter(test_dl_cifar))\n",
        "img = images[0].to(\"cuda\")\n",
        "label = labels[0].to(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  predLabel = torch.argmax(imgnet_cifar(img.view(1,-1))).item()\n",
        "\n",
        "#imshow(img.permute(1,2,0)) # permute because matplotlib's imshow expects (width,height,color) but we have (color,width,height)\n",
        "imshow(img)\n",
        "print(f\"Predicted label was: {testset_cifar.classes[predLabel]} ; Actual label was: {testset_cifar.classes[label]}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zmLGp5sXGrC",
        "colab_type": "text"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8lTEc_7WW9H",
        "colab_type": "text"
      },
      "source": [
        "Research into building new types of neural networks has advanced rapidly to solve a rich variety of different machine learning problems in the realms of computer vision, natural language processing, and many other contexts. These advances have lead to all sorts of new types of layers that have been implemented in pytorch.\n",
        "\n",
        "We'll look at the following concepts, the layers associated with them, and discuss the ideas behind them:\n",
        "- Pooling\n",
        "- BatchNorm\n",
        "- Dropout\n",
        "- Convolution\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtUX6eAKX2O9",
        "colab_type": "text"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8xJ-ccUQw08",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_tNbQ5UW3P",
        "colab_type": "text"
      },
      "source": [
        "# Example: Recognizing handwritten digits with a "
      ]
    }
  ]
}